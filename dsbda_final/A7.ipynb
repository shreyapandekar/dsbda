{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d5271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2894c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the below files if error occurs\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49955704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66ad4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Welcome to the Python Programming. at Indeed Insprining Infotech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e765e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29af6fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Welcome', 'to', 'the', 'Python', 'Programming', '.', 'at', 'Indeed', 'Insprining', 'Infotech']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12cffba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327d2e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  ['Welcome', 'to', 'the', 'Python', 'Programming', '.', 'at', 'Indeed', 'Insprining', 'Infotech']\n",
      "Filtered Tokens: ['Welcome', 'Python', 'Programming', '.', 'Indeed', 'Insprining', 'Infotech']\n"
     ]
    }
   ],
   "source": [
    "# Get the set of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize the text (assuming you have already tokenized it)\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Remove stop words from the tokens\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(\"Token: \",tokens)\n",
    "print(\"Filtered Tokens:\", filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd7d3bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Welcome to the Python Programming.', 'at Indeed Insprining Infotech']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38b50b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Tokenizer:  ['W', 'e', 'l', 'c', 'o', 'm', 'e', ' ', 't', 'o', ' ', 't', 'h', 'e', ' ', 'P', 'y', 't', 'h', 'o', 'n', ' ', 'P', 'r', 'o', 'g', 'r', 'a', 'm', 'm', 'i', 'n', 'g', '.', ' ', 'a', 't', ' ', 'I', 'n', 'd', 'e', 'e', 'd', ' ', 'I', 'n', 's', 'p', 'r', 'i', 'n', 'i', 'n', 'g', ' ', 'I', 'n', 'f', 'o', 't', 'e', 'c', 'h']\n"
     ]
    }
   ],
   "source": [
    "list_token=list(text)\n",
    "print(\"List Tokenizer: \",list_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f9629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 11001] getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b2aed57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Welcome', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('Python', 'NNP'),\n",
       " ('Programming', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('at', 'IN'),\n",
       " ('Indeed', 'RB'),\n",
       " ('Insprining', 'VBG'),\n",
       " ('Infotech', 'NNP')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags = nltk.pos_tag(tokens)\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d9cd5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean\n",
      "clean\n",
      "clean\n",
      "clean\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "words=['clean','cleaning','cleans','cleaned']\n",
    "ps = PorterStemmer()\n",
    "for w in words:\n",
    "    words=ps.stem(w)\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52f08018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming for  studies is studi\n",
      "Stemming for  studying is studi\n",
      "Stemming for  floors is floor\n",
      "Stemming for  cry is cri\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "texts  = \"studies studying floors cry\"\n",
    "tokenization = nltk.word_tokenize(texts)\n",
    "for w in tokenization:\n",
    "    print('Stemming for ', w,'is',porter_stemmer.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4904a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatization:\n",
      " ['Welcome', 'Python', 'Programming', '.', 'Indeed', 'Insprining', 'Infotech']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(\"\\nLemmatization:\\n\", lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7490b876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2753b8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma for  studies is study\n",
      "Lemma for  study is study\n",
      "Lemma for  floors is floor\n",
      "Lemma for  cry is cry\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "Wordnet_lemmatizer = WordNetLemmatizer()\n",
    "text  = \"studies study floors cry\"\n",
    "tokenization = nltk.word_tokenize(text)\n",
    "for w in tokenization:\n",
    "    print('Lemma for ', w,'is',Wordnet_lemmatizer.lemmatize(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e3a3eb",
   "metadata": {},
   "source": [
    "The\" is tagged as determiner (DT)\n",
    "\"quick\" and \"brown\" are tagged as adjectives (JJ)\n",
    "\"fox\" and \"dog\" are tagged as nouns (NN)\n",
    "\"jumps\" is tagged as a verb (VBZ)\n",
    "\"over\" is tagged as a preposition (IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8255f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if not word.lower() in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5d7772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "stemmed_tokens = [ps.stem(word) for word in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbe5faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "lemmatized_tokens = [wnl.lemmatize(word) for word in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "510bc446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  ['Welcome', 'to', 'the', 'Python', 'Programming', '.', 'at', 'Indeed', 'Insprining', 'Infotech']\n",
      "POS tags:  [('Welcome', 'VB'), ('to', 'TO'), ('the', 'DT'), ('Python', 'NNP'), ('Programming', 'NNP'), ('.', '.'), ('at', 'IN'), ('Indeed', 'RB'), ('Insprining', 'VBG'), ('Infotech', 'NNP')]\n",
      "Filtered tokens:  ['Welcome', 'Python', 'Programming', '.', 'Indeed', 'Insprining', 'Infotech']\n",
      "Stemmed tokens:  ['welcom', 'python', 'program', '.', 'inde', 'insprin', 'infotech']\n",
      "Lemmatized tokens:  ['Welcome', 'Python', 'Programming', '.', 'Indeed', 'Insprining', 'Infotech']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens: \", tokens)\n",
    "print(\"POS tags: \", pos_tags)\n",
    "print(\"Filtered tokens: \", filtered_tokens)\n",
    "print(\"Stemmed tokens: \", stemmed_tokens)\n",
    "print(\"Lemmatized tokens: \", lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed2cf7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6fe2aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_document = \"\"\"\n",
    "Natural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. \n",
    "As such, NLP is related to the area of human–computer interaction. \n",
    "Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edbc8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [sample_document]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61efba93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>area</th>\n",
       "      <th>artificial</th>\n",
       "      <th>as</th>\n",
       "      <th>between</th>\n",
       "      <th>challenges</th>\n",
       "      <th>computational</th>\n",
       "      <th>computer</th>\n",
       "      <th>computers</th>\n",
       "      <th>concerned</th>\n",
       "      <th>...</th>\n",
       "      <th>others</th>\n",
       "      <th>processing</th>\n",
       "      <th>related</th>\n",
       "      <th>science</th>\n",
       "      <th>such</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>understanding</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.262111</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.174741</td>\n",
       "      <td>0.174741</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.174741</td>\n",
       "      <td>0.174741</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.08737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        and     area  artificial       as  between  challenges  computational  \\\n",
       "0  0.262111  0.08737     0.08737  0.08737  0.08737     0.08737        0.08737   \n",
       "\n",
       "   computer  computers  concerned  ...   others  processing  related  science  \\\n",
       "0  0.174741   0.174741    0.08737  ...  0.08737     0.08737  0.08737  0.08737   \n",
       "\n",
       "      such     that       the        to  understanding     with  \n",
       "0  0.08737  0.08737  0.174741  0.174741        0.08737  0.08737  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
